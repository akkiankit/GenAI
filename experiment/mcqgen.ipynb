{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c161895-2aa6-48a6-84d6-a779208b064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1139c0f1-66de-45eb-bcbf-bbce4cf0254f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3bb493-cfbb-40ff-89bb-b353352860c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2990c04a-6243-4100-a3ee-ed07fb896f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimple roy\\Desktop\\MIT Deep Learning\\GenAI\\MCQ\\GenAI\\env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000233A3738BE0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000233A3747670>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(openai_api_key=key, model_name=\"gpt-3.5-turbo\", temperature =0.7)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "931ac91d-3baf-4ad5-93df-5b946b785a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbf27a4a-6001-438b-942b-c492838a2d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'mcq': 'multiple choice question', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}, '2': {'mcq': 'multiple choice question', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}, '3': {'mcq': 'multiple choice question', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}}\n"
     ]
    }
   ],
   "source": [
    "# we can put the above in respons.json file and read like below\n",
    "with open(\"..\\\\response.json\", \"r\") as f:\n",
    "    RESPONSE_JSON = json.load(f)\n",
    "\n",
    "print(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "070795f9-33d0-450e-9f4a-a914b933c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c4b8168-47db-40c1-9080-357d8657dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=Template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cf7a655-b5e5-49f4-92d3-d38e24f36f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d3c8eb1-897a-424e-9898-76db086f148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ca1be4d-39ee-43e0-b0c2-80946999dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=TEMPLATE2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8944dcc1-e70a-4109-bd02-715f8bae7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcb11118-e559-4ff6-94e7-48ee95899400",
   "metadata": {},
   "outputs": [],
   "source": [
    "genrate_evaluation_chain = SequentialChain(\n",
    "    chains=[quiz_chain, review_chain], \n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"], \n",
    "    output_variables=[\"quiz\", \"review\"], \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2af6ac2-66de-471c-a50f-561f5515480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"..\\\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "042f33e4-392d-4f67-9cdc-a1a74a1b00a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent progress in generative models have resulted in models that can produce realistic text, images and video that can potentially revolutionize the way humans work, create content and interact with machines. The workshop on Generative AI at AIMLSystems will focus on the entire life-cycle of building and deploying such Generative AI systems, including data collection and processing, developing systems and requisite infrastructure, applications it enables, and the ethics associated with such technology covering concerns related to fairness, transparency and accountability. We invite original, unpublished work on Artificial Intelligence with a focus on generative AI and their use cases. Specifically, the topics of interest include but are not limited to:\n",
      "\n",
      "Systems, architecture and infrastructure for Generative AI\n",
      "Machine learning and Modeling using LLMs and Diffusion models\n",
      "Large Language Models and its applications\n",
      "Multi-modal Generative AI and its applications\n",
      "Gen AI based Plugins and agents\n",
      "Deployment of Generative AI solutions\n",
      "Evaluation of Language and Diffusion based models\n",
      "Responsible use of Gen AI\n"
     ]
    }
   ],
   "source": [
    "with open(path,\"r\") as file:\n",
    "    text = file.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa1bc0b0-da3e-4e63-a0fd-687e2304809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text\n",
    "Number = 5\n",
    "Subject = \"AI\"\n",
    "Tone = \"Simple\"\n",
    "Response_Json = RESPONSE_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32bf2663-dbcb-440e-ad72-efd035454c91",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2911215402.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[46], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    with get_openai_callback() as cb:\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    genrate_evaluation_chain(\n",
    "\n",
    "        \"text\":text,\n",
    "        \"number\":Number,\n",
    "        \"subject\":Subject,\n",
    "        \"tone\":Tone,\n",
    "        \"response_json\": Response_Json\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b93dce-9578-43fd-8a1e-a853865400a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
